#!/usr/bin/env python3
"""
Script huáº¥n luyá»‡n mÃ´ hÃ¬nh LSTM vÃ  dá»± Ä‘oÃ¡n 20 ngÃ y tiáº¿p theo
Sá»­ dá»¥ng thÃ´ng sá»‘ máº·c Ä‘á»‹nh Ä‘Ã£ chá»‰ Ä‘á»‹nh
"""

import pandas as pd
import numpy as np
import pickle
import os
import json
from datetime import datetime, timedelta
from tensorflow.keras.callbacks import EarlyStopping
import warnings
warnings.filterwarnings('ignore')

# Import cÃ¡c hÃ m cáº§n thiáº¿t
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from data_utils import load_data, add_technical_indicators
from model_utils import preprocess_data, build_model, train_model, evaluate_model

# ===== CONSTANTS - Dá»… dÃ ng thay Ä‘á»•i =====
MODEL_TYPE = 'LSTM'  # Thay Ä‘á»•i thÃ nh 'GRU' náº¿u muá»‘n sá»­ dá»¥ng GRU

def main():
    print(f"ğŸš€ Báº¯t Ä‘áº§u huáº¥n luyá»‡n mÃ´ hÃ¬nh {MODEL_TYPE}...")
    
    # ===== THÃ”NG Sá» MÃ” HÃŒNH =====
    MODEL_CONFIG = {
        'model_type': MODEL_TYPE,
        'num_neurons': 64,
        'dropout_rate': 0.35,
        'num_hidden_layers': 2,
        'learning_rate': 0.001,
        'loss_fn': 'mae',
        'use_batch_norm': False
    }
    
    # ===== THÃ”NG Sá» HUáº¤N LUYá»†N =====
    TRAIN_CONFIG = {
        'epochs': 50,
        'batch_size': 32,
        'validation_split': 0.1,
        'time_step': 50
    }
    
    # ===== THÃ”NG Sá» Dá»® LIá»†U =====
    DATA_CONFIG = {
        'features_to_use': ['Close', 'Volume', 'RSI', 'MACD'],
        'target_column': 'Close',
        'scaler_type': 'minmax',
        'train_ratio': 0.8
    }
    
    PREDICTION_DAYS = 20
    
    print(f"ğŸ“Š Cáº¥u hÃ¬nh mÃ´ hÃ¬nh: {MODEL_CONFIG}")
    print(f"ğŸ“ˆ Cáº¥u hÃ¬nh huáº¥n luyá»‡n: {TRAIN_CONFIG}")
    print(f"ğŸ“‹ Cáº¥u hÃ¬nh dá»¯ liá»‡u: {DATA_CONFIG}")
    
    # ===== TÃ€I Dá»® LIá»†U =====
    print("\nğŸ“‚ Äang táº£i dá»¯ liá»‡u...")
    data = load_data('../data/VNI_2020_2025_FINAL.csv')
    print(f"âœ… ÄÃ£ táº£i {len(data)} dÃ²ng dá»¯ liá»‡u tá»« {data.index[0]} Ä‘áº¿n {data.index[-1]}")
    
    # ===== THÃŠM CHá»ˆ BÃO Ká»¸ THUáº¬T =====
    print("\nğŸ“ˆ Äang tÃ­nh toÃ¡n cÃ¡c chá»‰ bÃ¡o ká»¹ thuáº­t...")
    data_with_indicators = add_technical_indicators(data)
    
    # Kiá»ƒm tra dá»¯ liá»‡u sau khi thÃªm indicators
    print(f"âœ… ÄÃ£ thÃªm chá»‰ bÃ¡o ká»¹ thuáº­t. Dá»¯ liá»‡u hiá»‡n cÃ³ {len(data_with_indicators)} dÃ²ng")
    print(f"ğŸ“‹ CÃ¡c cá»™t: {list(data_with_indicators.columns)}")
    
    # Loáº¡i bá» dá»¯ liá»‡u thiáº¿u
    data_clean = data_with_indicators.dropna()
    print(f"ğŸ§¹ Sau khi loáº¡i bá» dá»¯ liá»‡u thiáº¿u: {len(data_clean)} dÃ²ng")
    
    # ===== CHUáº¨N Bá»Š Dá»® LIá»†U =====
    print("\nğŸ”„ Äang chuáº©n bá»‹ dá»¯ liá»‡u cho huáº¥n luyá»‡n...")
    X_train, y_train, X_test, y_test, scaler, scaled_data = preprocess_data(
        df=data_clean,
        features_to_use=DATA_CONFIG['features_to_use'],
        target_column=DATA_CONFIG['target_column'],
        time_step=TRAIN_CONFIG['time_step'],
        scaler_type=DATA_CONFIG['scaler_type'],
        train_ratio=DATA_CONFIG['train_ratio']
    )
    
    print(f"âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chuáº©n bá»‹:")
    print(f"   ğŸ“Š X_train shape: {X_train.shape}")
    print(f"   ğŸ“Š y_train shape: {y_train.shape}")
    print(f"   ğŸ“Š X_test shape: {X_test.shape}")
    print(f"   ğŸ“Š y_test shape: {y_test.shape}")
    
    # ===== XÃ‚Y Dá»°NG MÃ” HÃŒNH =====
    print("\nğŸ—ï¸ Äang xÃ¢y dá»±ng mÃ´ hÃ¬nh...")
    model = build_model(
        model_type=MODEL_CONFIG['model_type'],
        time_step=TRAIN_CONFIG['time_step'],
        num_features=len(DATA_CONFIG['features_to_use']),
        num_neurons=MODEL_CONFIG['num_neurons'],
        dropout_rate=MODEL_CONFIG['dropout_rate'],
        num_hidden_layers=MODEL_CONFIG['num_hidden_layers'],
        loss_fn=MODEL_CONFIG['loss_fn'],
        learning_rate=MODEL_CONFIG['learning_rate'],
        use_batch_norm=MODEL_CONFIG['use_batch_norm']
    )
    
    print("âœ… MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c xÃ¢y dá»±ng thÃ nh cÃ´ng!")
    model.summary()
    
    # ===== HUáº¤N LUYá»†N MÃ” HÃŒNH =====
    print("\nğŸ¯ Báº¯t Ä‘áº§u huáº¥n luyá»‡n mÃ´ hÃ¬nh...")
    
    # Callbacks
    callbacks = [
        EarlyStopping(
            monitor='val_loss',
            patience=10,
            restore_best_weights=True,
            verbose=1
        )
    ]
    
    history = train_model(
        model=model,
        X_train=X_train,
        y_train=y_train,
        config=TRAIN_CONFIG,
        callbacks=callbacks
    )
    
    print("âœ… Huáº¥n luyá»‡n hoÃ n thÃ nh!")
    
    # ===== ÄÃNH GIÃ MÃ” HÃŒNH =====
    print("\nğŸ“Š Äang Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh...")
    target_col_index = DATA_CONFIG['features_to_use'].index(DATA_CONFIG['target_column'])
    
    metrics, y_test_inv, y_pred_inv = evaluate_model(
        model=model,
        X_test=X_test,
        y_test=y_test,
        scaler=scaler,
        target_col_index=target_col_index
    )
    
    print("ğŸ“ˆ Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh:")
    for metric, value in metrics.items():
        print(f"   {metric}: {value:.4f}")
    
    # ===== LÆ¯U MÃ” HÃŒNH =====
    print("\nğŸ’¾ Äang lÆ°u mÃ´ hÃ¬nh...")
    
    # Táº¡o thÆ° má»¥c models náº¿u chÆ°a cÃ³
    os.makedirs('../models', exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    model_type_name = MODEL_CONFIG['model_type'].lower()  # lstm hoáº·c gru
    
    # LÆ°u model vá»›i tÃªn bao gá»“m loáº¡i mÃ´ hÃ¬nh
    model_path = f'../models/model_{model_type_name}_{timestamp}.h5'
    model.save(model_path)
    print(f"âœ… ÄÃ£ lÆ°u mÃ´ hÃ¬nh: {model_path}")
    
    # LÆ°u scaler
    scaler_path = f'../models/model_{model_type_name}_{timestamp}_scaler.pkl'
    with open(scaler_path, 'wb') as f:
        pickle.dump(scaler, f)
    print(f"âœ… ÄÃ£ lÆ°u scaler: {scaler_path}")
    
    # LÆ°u config
    config_path = f'../models/model_{model_type_name}_{timestamp}_config.pkl'
    config = {
        'model_config': MODEL_CONFIG,
        'train_config': TRAIN_CONFIG,
        'data_config': DATA_CONFIG,
        'metrics': metrics,
        'features_to_use': DATA_CONFIG['features_to_use'],
        'target_column': DATA_CONFIG['target_column']
    }
    with open(config_path, 'wb') as f:
        pickle.dump(config, f)
    print(f"âœ… ÄÃ£ lÆ°u cáº¥u hÃ¬nh: {config_path}")
    
    # ===== Dá»° ÄOÃN 20 NGÃ€Y TIáº¾P THEO =====
    print(f"\nğŸ”® Báº¯t Ä‘áº§u dá»± Ä‘oÃ¡n {PREDICTION_DAYS} ngÃ y tiáº¿p theo...")
    
    # Import hÃ m dá»± Ä‘oÃ¡n chuáº©n
    from predict_future import predict_future
    
    # Sá»­ dá»¥ng hÃ m predict_future chuáº©n
    predictions = predict_future(
        model=model,
        data=scaled_data,
        time_step=TRAIN_CONFIG['time_step'],
        n_future=PREDICTION_DAYS,
        scaler=scaler,
        num_features=len(DATA_CONFIG['features_to_use']),
        target_col_index=target_col_index,
        features_to_use=DATA_CONFIG['features_to_use']
    )
    
    # In káº¿t quáº£ dá»± Ä‘oÃ¡n
    for i, pred in enumerate(predictions):
        print(f"   NgÃ y {i+1}: {pred:.2f}")
    
    # ===== Táº O DATAFRAME Dá»° ÄOÃN =====
    # Táº¡o ngÃ y cho dá»± Ä‘oÃ¡n (chá»‰ ngÃ y giao dá»‹ch)
    last_date = data_clean.index[-1]
    future_dates = []
    days_added = 0
    current_date = last_date
    
    while days_added < PREDICTION_DAYS:
        current_date += timedelta(days=1)
        if current_date.weekday() < 5:  # 0=Mon, ..., 4=Fri
            future_dates.append(current_date)
            days_added += 1
    
    # Táº¡o DataFrame káº¿t quáº£
    prediction_df = pd.DataFrame({
        'Date': future_dates,
        'Predicted_Close': predictions
    })
    prediction_df.set_index('Date', inplace=True)
    
    print(f"\nğŸ¯ Dá»± Ä‘oÃ¡n {PREDICTION_DAYS} ngÃ y tiáº¿p theo:")
    print(prediction_df.round(2))
    
    # LÆ°u káº¿t quáº£ dá»± Ä‘oÃ¡n
    prediction_path = f'../models/predictions_{model_type_name}_{timestamp}.csv'
    prediction_df.to_csv(prediction_path)
    print(f"\nğŸ’¾ ÄÃ£ lÆ°u káº¿t quáº£ dá»± Ä‘oÃ¡n: {prediction_path}")
    
    print("\nğŸ‰ HoÃ n thÃ nh! MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n vÃ  dá»± Ä‘oÃ¡n thÃ nh cÃ´ng!")
    
    return {
        'model': model,
        'scaler': scaler,
        'metrics': metrics,
        'predictions': prediction_df,
        'model_path': model_path,
        'config': config
    }

if __name__ == "__main__":
    results = main()
